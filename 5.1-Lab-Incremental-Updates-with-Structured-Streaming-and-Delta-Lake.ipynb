{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42af51fd-bef4-47ca-bb96-53e5e488f554",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Processing Incremental Updates with Structured Streaming and Delta Lake\n",
    "In this lab you'll apply your knowledge of structured streaming and Auto Loader to implement a simple multi-hop architecture.\n",
    "\n",
    "#### 1.0. Import Shared Utilities and Data Files\n",
    "Run the following cell to setup necessary variables and clear out past runs of this notebook. Note that re-executing this cell will allow you to start the lab over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f02d4ec-6520-4906-bd69-9cd120265130",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping the database \"dbacademy_hy6ppm_virginia_edu_dewd_5_1\"\nRemoving the working directory \"dbfs:/user/hy6ppm@virginia.edu/dbacademy/dewd/5.1\"\n\nCreating the database \"dbacademy_hy6ppm_virginia_edu_dewd_5_1\"\n\nPredefined Paths:\n  DA.paths.working_dir: dbfs:/user/hy6ppm@virginia.edu/dbacademy/dewd/5.1\n  DA.paths.user_db:     dbfs:/user/hy6ppm@virginia.edu/dbacademy/dewd/5.1/5_1.db\n  DA.paths.checkpoints: dbfs:/user/hy6ppm@virginia.edu/dbacademy/dewd/5.1/_checkpoints\n\nPredefined tables in dbacademy_hy6ppm_virginia_edu_dewd_5_1:\n  -none-\n\nSetup completed in 4 seconds\n"
     ]
    }
   ],
   "source": [
    "%run ./Includes/5.1-Lab-setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "431e528d-711c-4144-9ed2-5875a0de7f24",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 2.0. Bronze Table: Ingest data\n",
    "This lab uses a collection of customer-related CSV data from DBFS found in */databricks-datasets/retail-org/customers/*.  Read this data using Auto Loader using its schema inference (use **`customersCheckpointPath`** to store the schema info). Stream the raw data to a Delta table called **`bronze`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "176594fc-08a2-4dde-b02f-095098cabd42",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "customers_checkpoint_path = f\"{DA.paths.checkpoints}/customers\"\n",
    "\n",
    "query = (spark.readStream\n",
    "              .format(\"cloudFiles\")\n",
    "              .option(\"cloudFiles.format\", \"csv\")\n",
    "              .option(\"cloudFiles.schemaLocation\", customers_checkpoint_path)\n",
    "              .load(\"/databricks-datasets/retail-org/customers/\")\n",
    "              .writeStream\n",
    "              .format(\"delta\")\n",
    "              .option(\"checkpointLocation\", customers_checkpoint_path)\n",
    "              .outputMode(\"append\")\n",
    "              .table(\"bronze\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e992ca75-1679-4b11-aab8-369b3bc5b7ea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DA.block_until_stream_is_ready(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60a19272-7a96-48f1-821a-3f97df06303e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### 2.1. Create a Streaming Temporary View\n",
    "Create a streaming temporary view into the bronze table so that we can perform transformations using SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03be6ed8-4bad-46b9-bb8b-bbb6a33c2f7a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(spark\n",
    "  .readStream\n",
    "  .table(\"bronze\")\n",
    "  .createOrReplaceTempView(\"bronze_temp\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "65e84cd0-c27e-4eb8-9bb5-d205b0894b17",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### 2.2. Clean and Enhance the Data\n",
    "Use the CTAS syntax to define a new streaming view called **`bronze_enhanced_temp`** that does the following:\n",
    "* Skips records with a null **`postcode`** (set to zero)\n",
    "* Inserts a column called **`receipt_time`** containing a current timestamp\n",
    "* Inserts a column called **`source_file`** containing the input filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fcd64fdd-9b5d-45bc-b641-b4162ceacb63",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- TODO:\n",
    "CREATE OR REPLACE TEMPORARY VIEW bronze_enhanced_temp AS\n",
    "SELECT\n",
    "  *, current_timestamp() receipt_time, input_file_name() source_file\n",
    "  FROM bronze_temp\n",
    "  WHERE postcode > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b00d377b-c499-4c5d-b72d-f3a992c8fc6f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 3.0. Silver Table\n",
    "Stream the data from **`bronze_enhanced_temp`** to a table called **`silver`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac90bbf8-c569-48ed-aa6f-59c6de0ffa42",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "silver_checkpoint_path = f\"{DA.paths.checkpoints}/silver\"\n",
    "\n",
    "query = (spark.table(\"bronze_enhanced_temp\")\n",
    "              .writeStream\n",
    "              .format(\"delta\")\n",
    "              .option(\"checkpointLocation\", silver_checkpoint_path)\n",
    "              .outputMode(\"append\")\n",
    "              .table(\"silver\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "269439ac-61dd-49ea-ae1a-e7fe22eb14b5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DA.block_until_stream_is_ready(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3db953ec-fbad-49f4-b4bf-2b2e87b7f102",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### 3.1. Create a Streaming Temporary View\n",
    "Create another streaming temporary view for the silver table so that we can perform business-level queries using SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "29fb7ae0-3cc4-4fdc-a39c-436888567478",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(spark\n",
    "  .readStream\n",
    "  .table(\"silver\")\n",
    "  .createOrReplaceTempView(\"silver_temp\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f627fdb-0801-466a-b551-cbb2475db2b9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 4.0. Gold Table\n",
    "Use the CTAS syntax to define a new streaming view called **`customer_count_temp`** that counts customers per state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae488156-8f83-4687-85c9-9ad0634d3070",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- TODO:\n",
    "CREATE OR REPLACE TEMPORARY VIEW customer_count_by_state_temp AS\n",
    "  SELECT state, count(state) AS customer_count\n",
    "  FROM silver_temp\n",
    "  GROUP BY state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d74549f-2c3a-4e8f-b09d-b3f9d884e1c9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Finally, stream the data from the **`customer_count_by_state_temp`** view to a Delta table called **`gold_customer_count_by_state`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93c5d8a0-882d-4657-a22f-6a52a4ff2f03",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "customers_count_checkpoint_path = f\"{DA.paths.checkpoints}/customers_counts\"\n",
    "\n",
    "query = (spark.table(\"customer_count_by_state_temp\")\n",
    "              .writeStream\n",
    "              .format(\"delta\")\n",
    "              .option(\"checkpointLocation\", customers_count_checkpoint_path)\n",
    "              .outputMode(\"complete\")\n",
    "              .table(\"gold_customer_count_by_state\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "853b65f6-afa4-43a8-b014-3d11115b02a0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DA.block_until_stream_is_ready(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca186f2a-62ff-4b1f-be75-936190dbd058",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 5.0. Query the Results\n",
    "Query the **`gold_customer_count_by_state`** table (this will not be a streaming query). Plot the results as a bar graph and also using the map plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12a846b2-8a76-4c20-accc-8a350befa08f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM gold_customer_count_by_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90cbf4de-2269-4a8a-9d23-be8128621149",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 6.0. Clean Up\n",
    "Run the following cell to remove the database and all data associated with this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2633ccc7-cde5-4fd1-8351-268d39b8d97e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DA.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27599803-99c9-411d-bb91-1f12d0c8a214",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "By completing this lab, you should now feel comfortable:\n",
    "* Using PySpark to configure Auto Loader for incremental data ingestion\n",
    "* Using Spark SQL to aggregate streaming data\n",
    "* Streaming data to a Delta table"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "5.1-Lab-Incremental-Updates-with-Structured-Streaming-and-Delta-Lake",
   "notebookOrigID": 1874827002782391,
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
